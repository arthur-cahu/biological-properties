{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import fig_ax, load_data, save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val, s_train_val, df_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send everything to numpy arrays\n",
    "X_train_val = df_train_val.to_numpy()\n",
    "y_train_val = s_train_val.to_numpy()\n",
    "X_test = df_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor, Lasso\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# build a list of dicts that says which classifier heads to test, and what params to test on them\n",
    "search_params = [\n",
    "    {\n",
    "        \"pca__n_components\": [50],\n",
    "        \"reg\": [LinearRegression()]  # our baseline: mean test score of -0.059320\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [150],\n",
    "        \"reg\": [Lasso(alpha=0.01)],  # -0.066543\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [50],\n",
    "        \"reg\": [Ridge()]  # -0.059013\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [250],\n",
    "        \"reg\": [SGDRegressor()]  # -0.060203\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [250],\n",
    "        \"reg\": [GaussianProcessRegressor()]  # -0.049241\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [250],\n",
    "        \"reg\": [svm.SVR(epsilon=3.6e-5, C=0.3, cache_size=1000)],  # -0.046590\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [250],\n",
    "        \"reg\": [svm.NuSVR(nu=1, C=0.3, cache_size=1000)],  # -0.046590; public score 0.0328\n",
    "        \"reg__nu\": [1],\n",
    "        \"reg__C\": [0.3]\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [50],\n",
    "        \"reg\": [RandomForestRegressor(n_estimators=1000)],  # -0.048581\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [50],\n",
    "        \"reg\": [ExtraTreesRegressor(n_estimators=1000)]  # -0.046971\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"pca__n_components\": [150],\n",
    "        \"reg\": [GradientBoostingRegressor(learning_rate=0.1)],  # -0.051251\n",
    "    },\n",
    "\n",
    "### NB: nous avons testé des grilles de paramètres pour chaque algorithme, par exemple:\n",
    "    # {\n",
    "    #     \"pca__n_components\": [50, 100, 150, 200, 250, \"mle\"],\n",
    "    #     \"reg\": [svm.SVR(cache_size=1000)],\n",
    "    #     \"epsilon\": np.logspace(-5, 0),\n",
    "    #     \"C\": np.logspace(-5, 0),\n",
    "    # },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"pca\", PCA(n_components=150)), # could also use \"mle\"\n",
    "    (\"reg\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and validation\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True).split(X_train_val, y_train_val)\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe,\n",
    "    search_params,\n",
    "    #n_iter=100,\n",
    "    cv=kf,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    pre_dispatch=\"2*n_jobs\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_train_val, y_train_val)\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the results\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "# results.sort_values(\"rank_test_score\", inplace=True)\n",
    "\n",
    "# let's make some room so we can visualise the results:\n",
    "results.drop(\n",
    "    columns=[f\"split{i}_test_score\" for i in range(5)]\n",
    "    + [\"std_fit_time\", \"mean_score_time\", \"std_score_time\", \"std_test_score\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the cross-validation results to csv\n",
    "cols_to_export = [\"param_reg\", \"param_pca__n_components\", \"mean_fit_time\", \"mean_test_score\"]\n",
    "results.sort_values(\"mean_test_score\", inplace=True, ascending=False)\n",
    "results[cols_to_export].to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = search.best_estimator_[0]\n",
    "regressor = search.best_estimator_[1]\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute predictions:\n",
    "y_pred = search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(y_pred, df_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ktyTBnp3PDa"
   },
   "source": [
    "### Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0EtbfFQmquAQ"
   },
   "outputs": [],
   "source": [
    "df_train_val, s_train_val, df_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwAc-PD5qvqk"
   },
   "outputs": [],
   "source": [
    "# send everything to numpy arrays\n",
    "X_train_val = df_train_val.to_numpy()\n",
    "y_train_val = s_train_val.to_numpy()\n",
    "X_test = df_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJf_p_VQ-bYe"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "pca = PCA(n_components= 150)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_val = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pEs4VAewwRu",
    "outputId": "e7a46d8c-db75-4461-ed89-f5b8176f4043"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohD8TElAuhBZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train),torch.Tensor(y_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val),torch.Tensor(y_val))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U36ayvjU1pDs",
    "outputId": "8b1e3f54-b31d-418f-ebc5-f33dff90abfa"
   },
   "outputs": [],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeTWro1Q3Xjh"
   },
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClrpcseXv88u"
   },
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regression, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "class Transformers_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformers_model, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        self.fc1 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x.unsqueeze(-1))\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxVpa3Ec3byA"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnfarXLvxyq1"
   },
   "outputs": [],
   "source": [
    "def validation(model, val_loader):\n",
    "  model.eval()\n",
    "  val_criterion = torch.nn.MSELoss(reduction = 'sum')\n",
    "  total_loss = 0.0\n",
    "  with tqdm(val_loader, unit=\"batch\") as batch:\n",
    "        for data, target in batch:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                loss = val_criterion(output, target)\n",
    "                total_loss += loss.item()\n",
    "  return total_loss/len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748,
     "referenced_widgets": [
      "ee1524287fdc48129f4210e39ae49c7a",
      "2d67a9c112754eaaa57265d380e778ba",
      "60511657674b4e32952444a4019d1b35",
      "cf51b1ca3a7247c7a5f9475bb56d6e56",
      "80c59f991e8c4bddaf7cd85db2dd6739",
      "d310a7a9ec164d8ca4f69dcad9f4df9a",
      "4f0ce2ee5e6d4d489c53a5aead150223",
      "677f9933b1ab4f298fc6b435331c3702",
      "2d86ba3689e44db5bff58beaaf8dd056",
      "3c834bbf411a44b397e9ef3f73d9c08b",
      "b639ae6643af4fb7b57007d7c894dddb",
      "207845ecaabf4f36b0c066a5408e525e",
      "9fa02a06da9248e6a857a40b248acf02",
      "cdd9e2f6fc934387b6611b8d9479eb16",
      "f0cea994712441db8acba57ce4a6517e",
      "7a060240d35a4832a54ad687674949c9",
      "505faf88345f402180eefe802231dd8d",
      "c18bf421556e42f298229a6f050a27cb",
      "34ae258057dc4d50895f02c9e6f257e5",
      "f72afca68a5d46ad9cd056ae5861429f",
      "9c6302a877344661ab38d49f461ba46e",
      "595049dfb99f45a89d12eb8f5cf18ed7",
      "e619508099294e109190f43b712e2601",
      "873840b83ea1446f8c8b248a40e3f424",
      "8299cdde493949f3aa201df3da4612b0",
      "a615d014a5184809ab7a18aa4031bb61",
      "eb2311e17f5e470f8a43fe3e3e6bccbe",
      "c255ece30aae4ef880aa71d4b8f2add4",
      "ef48c3eab57849d9ae9a2c6a529536aa",
      "a2c860eadc9f4289af12b34df816c94e",
      "96530cee76dc4ca99d7f64b451d6dc99",
      "779b077aeddd4f6fa4214808bbd4568b",
      "0d566a4517c242118974187c556c8e51",
      "358a0f1687b14bee82f5a05f9ee80f58",
      "57d82d28ef5a47a2a610bae8bbe54d59",
      "4dfb4ded3ec344e89bc60f1dc74a088f",
      "3f92a5ecb1bc45c79b92569f08298b44",
      "dc0e8df5f5b1434d9d89bc7f2c9c9b65",
      "003f83f8f647426bac8c37d566a93c32",
      "f31cde662f8d4adfbe140b13a3f5ac05",
      "c770c65d1bc54544baab79bdcf8a28e1",
      "7974148e90d94bb78b1b6baadf010379",
      "de18f11011c1472c8ee67b32f35ab030",
      "d4a76ec4e2594517a811e37752cc35a0",
      "154475b456d94d329855c3864aacb7d4",
      "b042cede750943269e9cf90c1740de5e",
      "44386b00f1664ff3a051ebfa8a4a7769",
      "ccd71296a95d41698611e26560e6dc6f",
      "fac491df00a24ea1ba90e302045a08cc",
      "0366cce1a63647c9b1d5b4171101334a",
      "2ec12fdc0210441e8791fe73d5a186e3",
      "f4ddac1339314343adfe46e45210b3be",
      "f5751d9cdbc249a39fcf946421599d7e",
      "c1cfe4124c78421b8a52f625d8b37e4a",
      "15ab39fb5491482eb611c5dfd8b2b8ed",
      "60e4e857432f48d5a4087538bf8646e8",
      "35d84928d6d84cb79cc0bb2761f0508a",
      "12cc7c911d4346dbb84c7c37f9116e10",
      "45931c2b851344468492f720ed63e2ef",
      "d3584327a2e54224b7120174133eca52",
      "101f646f8fd5478994587b16c1e4c3e9",
      "8ffd5813656c4ee8b0600025ea5bccb2",
      "40fd837641ee4704a7575ec9714424bc",
      "d4a4fa544fc34cbfb8946946b492c701",
      "53fa423aee7b488abdba7429b50ff4f1",
      "f23adb46cd0f490588743f03dfd7624b",
      "6338c401c2034bfb9481c95be26645c3",
      "a73b790e02cc40d8a2b7a26bf77fb9a2",
      "998bc28ff14f46f29488e7a77ef898e1",
      "cd8abd7348a6407dab75866f34ac579a",
      "1d30c84567e9466a826d4664d7ddfcee",
      "156c6dab55914b0482875fc9a45f420b",
      "004639fac8e44a5b9802df917560bfde",
      "fecdf34683894626b8e5fc4f0dc9a07b",
      "5f126e4e37a4486893e7f52f638a6685",
      "7000545ea07f4f8dac620e89026afade",
      "4f53bd51c081481896be4544c199fdb9"
     ]
    },
    "id": "3xffAmW4sh5a",
    "outputId": "b66ca491-ef70-436c-81a5-90cdfed357d8"
   },
   "outputs": [],
   "source": [
    "#model = Regression()\n",
    "model = Net()\n",
    "#model = Transformers_model()\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.to(device)\n",
    "best_val_loss = float(\"inf\")\n",
    "best_weights = None\n",
    "model.train()\n",
    "for epoch in range(1, 50):\n",
    "    total_loss = 0.0\n",
    "    learning_rate = 0.01 / (epoch + 1)\n",
    "    model.train()\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = torch.reshape(model(data), (1,))\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tepoch.set_postfix({'Loss': total_loss / len(val_dataset), 'Learning Rate': learning_rate})\n",
    "    val_loss = validation(model, val_loader)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_weights = deepcopy(model.state_dict())\n",
    "    print(f\"Val loss: {val_loss}\\tBest val loss: {best_val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-HYWko7qxk2"
   },
   "outputs": [],
   "source": [
    "# compute predictions:\n",
    "model.load_state_dict(best_weights)\n",
    "test_transformed = pca.transform(X_test)\n",
    "y_pred = []\n",
    "for batch in test_transformed:\n",
    "    test_tensor = torch.tensor(batch)\n",
    "    test_tensor = test_tensor.reshape(1, -1).to(device).to(dtype=torch.float32)\n",
    "    y_pred.append(model(test_tensor).item())\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qa2iQTw5qzYY"
   },
   "outputs": [],
   "source": [
    "save_results(y_pred, df_test.index)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec098f3f8c662b53cb495a99f3bdf670fa1052aa811a9729b1f28e0384e8235b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
